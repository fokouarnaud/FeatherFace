{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeatherFace Baseline Training and Evaluation\n",
    "\n",
    "This notebook reproduces the original FeatherFace training process following the author's instructions.\n",
    "\n",
    "## Overview\n",
    "- Model: FeatherFace with MobileNetV1 0.25x backbone\n",
    "- Dataset: WIDERFace (auto-download)\n",
    "- Expected Results: 0.49M parameters, 90.8% mAP\n",
    "- Uses original training scripts for faithful reproduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths - all paths are relative to the FeatherFace root directory\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the project root directory (parent of notebooks/)\n",
    "PROJECT_ROOT = Path(os.path.abspath('..'))\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Change to project root for all operations\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install project in editable mode\n",
    "!pip install -e .\n",
    "\n",
    "# Verify imports work\n",
    "try:\n",
    "    from models.retinaface import RetinaFace\n",
    "    from data import cfg_mnet, WiderFaceDetection\n",
    "    print(\"✓ Imports successful\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ Import error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify imports and check GPU\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gdown\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Download and Preparation\n",
    "\n",
    "The dataset will be automatically downloaded when training starts. But we can prepare the directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and create data directories\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create necessary directories\n",
    "data_dir = Path('data/widerface')\n",
    "weights_dir = Path('weights')\n",
    "results_dir = Path('results')\n",
    "\n",
    "\n",
    "# WIDERFace download links\n",
    "WIDERFACE_GDRIVE_ID = '11UGV3nbVv1x9IC--_tK3Uxf7hA6rlbsS'\n",
    "WIDERFACE_URL = f'https://drive.google.com/uc?id={WIDERFACE_GDRIVE_ID}'\n",
    "\n",
    "for dir_path in [data_dir, weights_dir, results_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"✓ Directory ready: {dir_path}\")\n",
    "\n",
    "\n",
    "def download_widerface():\n",
    "    \"\"\"Download WIDERFace dataset from Google Drive\"\"\"\n",
    "    output_path ='..'/ data_dir / 'widerface.zip'\n",
    "    \n",
    "    if not output_path.exists():\n",
    "        print(\"Downloading WIDERFace dataset...\")\n",
    "        print(\"This may take several minutes depending on your connection.\")\n",
    "        \n",
    "        try:\n",
    "            gdown.download(WIDERFACE_URL, str(output_path), quiet=False)\n",
    "            print(f\"✓ Downloaded to {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Download failed: {e}\")\n",
    "            print(\"Please download manually from:\")\n",
    "            print(f\"  {WIDERFACE_URL}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"✓ Dataset already downloaded: {output_path}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Download dataset\n",
    "if download_widerface():\n",
    "    print(\"\\n✅ Dataset download complete!\")\n",
    "else:\n",
    "    print(\"\\n❌ Please download the dataset manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset\n",
    "def extract_widerface():\n",
    "    \"\"\"Extract WIDERFace dataset\"\"\"\n",
    "    zip_path = '..'/data_dir / 'widerface.zip'\n",
    "    \n",
    "    if not zip_path.exists():\n",
    "        print(\"❌ Dataset zip file not found. Please download first.\")\n",
    "        return False\n",
    "    \n",
    "    # Check if already extracted\n",
    "    if (data_dir / 'train' / 'label.txt').absolute().exists() and \\\n",
    "       (data_dir / 'val' / 'wider_val.txt').absolute().exists():\n",
    "        print(\"✓ Dataset already extracted\")\n",
    "        return True\n",
    "    \n",
    "    print(\"Extracting dataset...\")\n",
    "    try:\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(data_dir)\n",
    "        print(\"✓ Dataset extracted successfully\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Extraction failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Extract dataset\n",
    "if extract_widerface():\n",
    "    print(\"\\n✅ Dataset ready for use!\")\n",
    "else:\n",
    "    print(\"\\n❌ Please extract the dataset manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset structure\n",
    "def verify_dataset():\n",
    "    \"\"\"Verify WIDERFace dataset structure\"\"\"\n",
    "    required_files = [\n",
    "        data_dir / 'train' / 'label.txt',\n",
    "        data_dir / 'val' / 'wider_val.txt'\n",
    "    ]\n",
    "    \n",
    "    all_present = True\n",
    "    for file_path in required_files:\n",
    "        if file_path.absolute().exists():\n",
    "            print(f\"✓ Found: {file_path.absolute()}\")\n",
    "        else:\n",
    "            print(f\"✗ Missing: {file_path.absolute()}\")\n",
    "            all_present = False\n",
    "    \n",
    "    # Check for images\n",
    "    for split in ['train', 'val']:\n",
    "        img_dir = data_dir / split / 'images'\n",
    "        if img_dir.exists():\n",
    "            img_count = len(list(img_dir.glob('**/*.jpg')))\n",
    "            print(f\"✓ {split} images: {img_count} found\")\n",
    "        else:\n",
    "            print(f\"✗ {split} images directory not found\")\n",
    "            all_present = False\n",
    "    \n",
    "    return all_present\n",
    "\n",
    "dataset_ready = verify_dataset()\n",
    "print(f\"\\nDataset verification: {'PASSED ✅' if dataset_ready else 'FAILED ❌'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Download Pre-trained Weights\n",
    "\n",
    "The model requires pre-trained MobileNetV1 0.25x weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained weights info\n",
    "PRETRAIN_FILENAME = 'mobilenetV1X0.25_pretrain.tar'\n",
    "pretrain_path = weights_dir / PRETRAIN_FILENAME\n",
    "\n",
    "print(\"=== Pre-trained Weights Download Instructions ===\")\n",
    "print(f\"\\nWeights should be placed at: {pretrain_path.absolute()}\")\n",
    "print(\"\\nDownload from:\")\n",
    "print(\"https://drive.google.com/open?id=1oZRSG0ZegbVkVwUd8wUIQx8W7yfZ_ki1\")\n",
    "print(f\"\\nSave as: {pretrain_path.relative_to('.')}\")\n",
    "\n",
    "if pretrain_path.exists():\n",
    "    print(f\"\\n✓ Pre-trained weights found: {pretrain_path.relative_to('.')}\")\n",
    "else:\n",
    "    print(f\"\\n✗ Pre-trained weights not found. Please download manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Configuration and Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters from original repository\n",
    "TRAIN_CONFIG = {\n",
    "    'network': 'mobile0.25',\n",
    "    'num_workers': 1,  # Adjust based on your system\n",
    "    'lr': 1e-3,\n",
    "    'momentum': 0.9,\n",
    "    'save_folder': 'weights/',\n",
    "    'resume_net': None,  # Will be set to pretrained weights\n",
    "    'batch_size': 32,\n",
    "    'num_epoch': 250,\n",
    "    'gpu': True,\n",
    "    'ngpu': 1,\n",
    "    'pretrain': True\n",
    "}\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "for key, value in TRAIN_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Process\n",
    "\n",
    "We'll use the original train.py script with our configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training command\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Build command arguments\n",
    "train_args = [\n",
    "    sys.executable, 'train.py',\n",
    "    '--network', TRAIN_CONFIG['network'],\n",
    "    '--num_workers', str(TRAIN_CONFIG['num_workers']),\n",
    "    '--lr', str(TRAIN_CONFIG['lr']),\n",
    "    '--momentum', str(TRAIN_CONFIG['momentum']),\n",
    "    '--save_folder', TRAIN_CONFIG['save_folder'],\n",
    "    '--batch_size', str(TRAIN_CONFIG['batch_size']),\n",
    "    '--num_epoch', str(TRAIN_CONFIG['num_epoch'])\n",
    "]\n",
    "\n",
    "if TRAIN_CONFIG['gpu']:\n",
    "    train_args.extend(['--gpu', '--ngpu', str(TRAIN_CONFIG['ngpu'])])\n",
    "\n",
    "if TRAIN_CONFIG['pretrain']:\n",
    "    train_args.append('--pretrain')\n",
    "\n",
    "print(\"Training command:\")\n",
    "print(' '.join(train_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Run training directly (recommended for full training)\n",
    "# Uncomment to run:\n",
    "# result = subprocess.run(train_args, capture_output=True, text=True)\n",
    "# print(result.stdout)\n",
    "# if result.stderr:\n",
    "#     print(\"Errors:\", result.stderr)\n",
    "\n",
    "# Option 2: Show manual command for terminal execution\n",
    "print(\"\\n=== To train manually in terminal ===\")\n",
    "print(\"Navigate to project root and run:\")\n",
    "print(' '.join(train_args).replace(sys.executable, 'python'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation on WIDERFace\n",
    "\n",
    "After training completes, we evaluate the model using test_widerface.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for trained model\n",
    "import glob\n",
    "\n",
    "# Find the latest checkpoint\n",
    "checkpoints = sorted(glob.glob('weights/mobilenet0.25_*.pth'))\n",
    "if checkpoints:\n",
    "    latest_checkpoint = checkpoints[-1]\n",
    "    print(f\"Found checkpoint: {latest_checkpoint}\")\n",
    "else:\n",
    "    print(\"No checkpoints found. Please train the model first.\")\n",
    "    latest_checkpoint = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation parameters\n",
    "EVAL_CONFIG = {\n",
    "    'trained_model': latest_checkpoint or 'weights/mobilenet0.25_Final.pth',\n",
    "    'network': 'mobile0.25',\n",
    "    'confidence_threshold': 0.02,\n",
    "    'top_k': 5000,\n",
    "    'nms_threshold': 0.4,\n",
    "    'keep_top_k': 750,\n",
    "    'save_folder': 'results/',\n",
    "    'gpu': True\n",
    "}\n",
    "\n",
    "print(\"Evaluation Configuration:\")\n",
    "for key, value in EVAL_CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build evaluation command\n",
    "eval_args = [\n",
    "    sys.executable, 'test_widerface.py',\n",
    "    '--trained_model', EVAL_CONFIG['trained_model'],\n",
    "    '--network', EVAL_CONFIG['network'],\n",
    "    '--confidence_threshold', str(EVAL_CONFIG['confidence_threshold']),\n",
    "    '--top_k', str(EVAL_CONFIG['top_k']),\n",
    "    '--nms_threshold', str(EVAL_CONFIG['nms_threshold']),\n",
    "    '--keep_top_k', str(EVAL_CONFIG['keep_top_k']),\n",
    "    '--save_folder', EVAL_CONFIG['save_folder']\n",
    "]\n",
    "\n",
    "if EVAL_CONFIG['gpu']:\n",
    "    eval_args.append('--gpu')\n",
    "\n",
    "print(\"Evaluation command:\")\n",
    "print(' '.join(eval_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option to run evaluation\n",
    "print(\"\\n=== To evaluate manually in terminal ===\")\n",
    "print(\"Navigate to project root and run:\")\n",
    "print(' '.join(eval_args).replace(sys.executable, 'python'))\n",
    "\n",
    "# The evaluation will generate prediction files in results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Analysis\n",
    "\n",
    "Let's analyze the model architecture and count parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze model\n",
    "import torch\n",
    "from models.retinaface import RetinaFace\n",
    "from data import cfg_mnet\n",
    "\n",
    "# Create model\n",
    "net = RetinaFace(cfg=cfg_mnet, phase='test')\n",
    "\n",
    "# Count parameters\n",
    "def count_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "total, trainable = count_parameters(net)\n",
    "print(f\"Total parameters: {total:,} ({total/1e6:.2f}M)\")\n",
    "print(f\"Trainable parameters: {trainable:,} ({trainable/1e6:.2f}M)\")\n",
    "\n",
    "# Expected: ~0.49M parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze model architecture by module\n",
    "print(\"\\n=== Model Architecture Analysis ===\")\n",
    "for name, module in net.named_children():\n",
    "    params = sum(p.numel() for p in module.parameters())\n",
    "    print(f\"{name}: {params:,} parameters ({params/1e6:.3f}M)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Results Summary\n",
    "\n",
    "After running the evaluation, compare with expected baseline results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected baseline results\n",
    "baseline_results = {\n",
    "    'Model': 'FeatherFace (MobileNetV1 0.25x)',\n",
    "    'Parameters': '0.49M',\n",
    "    'WIDERFace Easy': '90.8%',\n",
    "    'WIDERFace Medium': '88.2%',\n",
    "    'WIDERFace Hard': '77.2%',\n",
    "    'Average mAP': '85.4%'\n",
    "}\n",
    "\n",
    "print(\"=== Expected Baseline Results ===\")\n",
    "for metric, value in baseline_results.items():\n",
    "    print(f\"{metric}: {value}\")\n",
    "\n",
    "print(\"\\n=== Your Results ===\")\n",
    "print(\"Check results/ directory for evaluation outputs\")\n",
    "print(\"Use evaluation tools to compute mAP scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Next Steps - FeatherFace V2\n",
    "\n",
    "With baseline established, we can proceed to Phase 02 for FeatherFace V2 development:\n",
    "\n",
    "1. **Architecture Optimizations**:\n",
    "   - Replace standard convolutions with grouped/depthwise convolutions\n",
    "   - Implement CBAM++ attention modules\n",
    "   - Optimize FPN with lightweight operations\n",
    "\n",
    "2. **Target Specifications**:\n",
    "   - Parameters: 0.25M (50% reduction)\n",
    "   - Performance: 92%+ mAP (1.2% improvement)\n",
    "   - Maintain real-time inference speed\n",
    "\n",
    "3. **Implementation Plan**:\n",
    "   - Create new model variant in models/\n",
    "   - Implement optimized modules in layers/\n",
    "   - Train with enhanced augmentation\n",
    "   - Fine-tune hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
