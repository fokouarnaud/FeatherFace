{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeatherFace Baseline Training and Evaluation\n",
    "\n",
    "This notebook reproduces the original FeatherFace training process following the author's instructions.\n",
    "\n",
    "## Overview\n",
    "- Model: FeatherFace with MobileNetV1 0.25x backbone\n",
    "- Dataset: WIDERFace (auto-download)\n",
    "- Expected Results: 0.49M parameters, 90.8% mAP\n",
    "- Uses original training scripts for faithful reproduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup paths - all paths are relative to the FeatherFace root directory\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Get the project root directory (parent of notebooks/)\n",
    "PROJECT_ROOT = Path(os.path.abspath('..'))\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# Change to project root for all operations\n",
    "os.chdir(PROJECT_ROOT)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies from project root\n",
    "!pip install -e .\n",
    "!pip install gdown requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify imports and check GPU\n",
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gdown\n",
    "import requests\n",
    "import zipfile\n",
    "import tarfile\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Preparation - WIDERFace\n",
    "\n",
    "Download and organize the WIDERFace dataset in the correct location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directories in the correct location (project root)\n",
    "data_root = Path('./data/widerface')\n",
    "data_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Data directory: {data_root.absolute()}\")\n",
    "print(f\"Train images will be in: {data_root.absolute()}/train/images/\")\n",
    "print(f\"Val images will be in: {data_root.absolute()}/val/images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIDERFace download information\n",
    "print(\"\"\"=== WIDERFace Dataset Download Instructions ===\")\n",
    "print(\"\\nThe dataset needs to be downloaded and organized as follows:\")\n",
    "print(\"\\n1. Download from Google Drive:\")\n",
    "print(\"   https://drive.google.com/open?id=11UGV3nbVv1x9IC--_tK3Uxf7hA6rlbsS\")\n",
    "print(\"   \")\n",
    "print(\"   OR from Baidu Cloud:\")\n",
    "print(\"   https://pan.baidu.com/s/1jIp9t30oYivrAvrgUgIoLQ (Password: ruck)\")\n",
    "print(\"\\n2. Extract the downloaded file to:\")\n",
    "print(f\"   {data_root.absolute()}\")\n",
    "print(\"\\n3. The structure should be:\")\n",
    "print(\"   data/widerface/\")\n",
    "print(\"     train/\")\n",
    "print(\"       images/\")\n",
    "print(\"       label.txt\")\n",
    "print(\"     val/\")\n",
    "print(\"       images/\")\n",
    "print(\"       wider_val.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic download with gdown (optional)\n",
    "def download_widerface():\n",
    "    \"\"\"Attempt to download WIDERFace dataset\"\"\"\n",
    "    WIDERFACE_GDRIVE_ID = '11UGV3nbVv1x9IC--_tK3Uxf7hA6rlbsS'\n",
    "    output_path = data_root / 'widerface.zip'\n",
    "    \n",
    "    if output_path.exists():\n",
    "        print(f\"✓ Dataset zip already exists: {output_path}\")\n",
    "        return True\n",
    "    \n",
    "    print(\"Attempting automatic download...\")\n",
    "    print(\"Note: This may fail due to Google Drive restrictions.\")\n",
    "    print(\"If it fails, please download manually using the links above.\")\n",
    "    \n",
    "    try:\n",
    "        url = f'https://drive.google.com/uc?id={WIDERFACE_GDRIVE_ID}'\n",
    "        gdown.download(url, str(output_path), quiet=False)\n",
    "        print(f\"✓ Downloaded to {output_path}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Automatic download failed: {e}\")\n",
    "        print(\"Please download manually using the links provided above.\")\n",
    "        return False\n",
    "\n",
    "# Try automatic download\n",
    "download_success = download_widerface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify dataset structure\n",
    "def verify_dataset():\n",
    "    \"\"\"Verify WIDERFace dataset structure\"\"\"\n",
    "    required_files = [\n",
    "        data_root / 'train' / 'label.txt',\n",
    "        data_root / 'val' / 'wider_val.txt'\n",
    "    ]\n",
    "    \n",
    "    print(\"Checking dataset structure...\")\n",
    "    all_present = True\n",
    "    \n",
    "    for file_path in required_files:\n",
    "        if file_path.exists():\n",
    "            print(f\"✓ Found: {file_path.relative_to('.')}\")\n",
    "        else:\n",
    "            print(f\"✗ Missing: {file_path.relative_to('.')}\")\n",
    "            all_present = False\n",
    "    \n",
    "    # Check for images\n",
    "    for split in ['train', 'val']:\n",
    "        img_dir = data_root / split / 'images'\n",
    "        if img_dir.exists():\n",
    "            # Count jpg files recursively\n",
    "            img_count = len(list(img_dir.rglob('*.jpg')))\n",
    "            print(f\"✓ {split} images: {img_count} found in {img_dir.relative_to('.')}\")\n",
    "        else:\n",
    "            print(f\"✗ {split} images directory not found: {img_dir.relative_to('.')}\")\n",
    "            all_present = False\n",
    "    \n",
    "    return all_present\n",
    "\n",
    "dataset_ready = verify_dataset()\n",
    "print(f\"\\nDataset verification: {'PASSED ✅' if dataset_ready else 'FAILED ❌'}\")\n",
    "\n",
    "if not dataset_ready:\n",
    "    print(\"\\nPlease download and extract the dataset manually before continuing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pre-trained Weights Download\n",
    "\n",
    "Download the MobileNetV1 0.25x pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weights directory\n",
    "weights_dir = Path('./weights')\n",
    "weights_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Pre-trained weights info\n",
    "PRETRAIN_FILENAME = 'mobilenetV1X0.25_pretrain.tar'\n",
    "pretrain_path = weights_dir / PRETRAIN_FILENAME\n",
    "\n",
    "print(\"=== Pre-trained Weights Download Instructions ===\")\n",
    "print(f\"\\nWeights should be placed at: {pretrain_path.absolute()}\")\n",
    "print(\"\\nDownload from:\")\n",
    "print(\"https://drive.google.com/open?id=1oZRSG0ZegbVkVwUd8wUIQx8W7yfZ_ki1\")\n",
    "print(f\"\\nSave as: {pretrain_path.relative_to('.')}\")\n",
    "\n",
    "if pretrain_path.exists():\n",
    "    print(f\"\\n✓ Pre-trained weights found: {pretrain_path.relative_to('.')}\")\n",
    "else:\n",
    "    print(f\"\\n✗ Pre-trained weights not found. Please download manually.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration Check\n",
    "\n",
    "Check the network configuration as mentioned in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import configuration from data/config.py\n",
    "from data import cfg_mnet\n",
    "\n",
    "# Display configuration\n",
    "print(\"=== FeatherFace Configuration (cfg_mnet) ===\")\n",
    "print(f\"Network name: {cfg_mnet['name']}\")\n",
    "print(f\"Input image size: {cfg_mnet['image_size']}\")\n",
    "print(f\"Batch size: {cfg_mnet['batch_size']}\")\n",
    "print(f\"Learning rate: {cfg_mnet['lr']}\")\n",
    "print(f\"Training epochs: {cfg_mnet['epoch']}\")\n",
    "print(f\"GPU train: {cfg_mnet['gpu_train']}\")\n",
    "print(f\"\\nMin sizes: {cfg_mnet['min_sizes']}\")\n",
    "print(f\"Steps: {cfg_mnet['steps']}\")\n",
    "print(f\"Variance: {cfg_mnet['variance']}\")\n",
    "print(f\"Clip: {cfg_mnet['clip']}\")\n",
    "print(f\"Loc weight: {cfg_mnet['loc_weight']}\")\n",
    "print(f\"\\nNote: You can modify these in data/config.py before training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Using Original Scripts (Recommended)\n",
    "\n",
    "The author provides a training script that should be used for faithful reproduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training command\n",
    "print(\"=== Training Instructions ===\")\n",
    "print(\"\\nTo train the model, run this command in the terminal from the project root:\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CUDA_VISIBLE_DEVICES=0 torchrun --standalone --nproc_per_node=1 train.py --network mobile0.25\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nThis will:\")\n",
    "print(\"- Use GPU 0 for training\")\n",
    "print(\"- Train the MobileNet 0.25x model\")\n",
    "print(\"- Save checkpoints to ./weights/\")\n",
    "print(\"- Train for\", cfg_mnet['epoch'], \"epochs\")\n",
    "print(\"\\nAlternatively, you can run from this notebook:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training from notebook (uncomment to execute)\n",
    "# Note: This will take several hours for full training\n",
    "\n",
    "# import subprocess\n",
    "# import os\n",
    "# \n",
    "# # Set GPU\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "# \n",
    "# # Run training\n",
    "# cmd = ['torchrun', '--standalone', '--nproc_per_node=1', 'train.py', '--network', 'mobile0.25']\n",
    "# print(f\"Running: {' '.join(cmd)}\")\n",
    "# subprocess.run(cmd, cwd=PROJECT_ROOT)"
   ]
  }