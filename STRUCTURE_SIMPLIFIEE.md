# FeatherFace - Structure SimplifiÃ©e

## ğŸ¯ Architecture Claire et Ã‰purÃ©e

Cette structure simplifiÃ©e permet une comparaison directe et claire entre V1 Original et V2 Innovation.

## ğŸ“ Structure Finale

```
FeatherFace/
â”œâ”€â”€ ğŸ”§ models/                    # ModÃ¨les principaux
â”‚   â”œâ”€â”€ net.py                    # Composants de base (MobileNet, BiFPN, CBAM, SSH)
â”‚   â”œâ”€â”€ retinaface.py            # V1 Original (502K params, 6 CBAM modules)
â”‚   â”œâ”€â”€ featherface_v2.py        # V2 Innovation (493K params, 3 Coordinate Attention)
â”‚   â””â”€â”€ attention_v2.py          # Module Coordinate Attention
â”œâ”€â”€ ğŸš€ Scripts d'entraÃ®nement:
â”‚   â”œâ”€â”€ train_v1.py              # EntraÃ®nement V1 Original
â”‚   â””â”€â”€ train_v2.py              # EntraÃ®nement V2 Innovation
â”œâ”€â”€ ğŸ“Š data/                     # Dataset et configurations
â”‚   â”œâ”€â”€ config.py                # cfg_mnet (V1) et cfg_v2 (V2)
â”‚   â””â”€â”€ widerface/               # Dataset WIDERFace
â””â”€â”€ ğŸ“š Documentation:
    â”œâ”€â”€ README.md                # Documentation principale
    â”œâ”€â”€ CLAUDE.md                # Instructions Claude
    â””â”€â”€ docs/                    # Documentation dÃ©taillÃ©e
```

## âš¡ Utilisation SimplifiÃ©e

### EntraÃ®ner V1 Original (Baseline)
```bash
python train_v1.py --training_dataset ./data/widerface/train/label.txt --network mobile0.25
```

### EntraÃ®ner V2 Innovation
```bash
python train_v2.py --training_dataset ./data/widerface/train/label.txt --network v2
```

## ğŸ”¬ Comparaison Scientifique

| Aspect | V1 Original | V2 Innovation |
|--------|-------------|---------------|
| **Fichier** | `models/retinaface.py` | `models/featherface_v2.py` |
| **Script** | `train_v1.py` | `train_v2.py` |
| **ParamÃ¨tres** | 502K | 493K (-1.8%) |
| **Attention** | 6 CBAM modules | 3 Coordinate Attention |
| **Config** | `cfg_mnet` | `cfg_v2` |
| **Innovation** | Baseline GitHub | Coordinate Attention |

## âœ… Avantages de cette Structure

1. **ClartÃ© Maximale** : 2 modÃ¨les, 2 scripts, comparaison directe
2. **MÃ©thodologie Claire** : V1 Original â†’ V2 Innovation
3. **ReproductibilitÃ©** : Scripts indÃ©pendants et configurations claires
4. **Maintenance Simple** : Moins de fichiers, moins de confusion
5. **Comparaison Scientifique** : Changement contrÃ´lÃ© (CBAM â†’ Coordinate Attention)

## ğŸ¯ Points ClÃ©s

- **V1 Original** : ImplÃ©mentation fidÃ¨le du repository GitHub avec 6 CBAM
- **V2 Innovation** : Remplacement des 6 CBAM par 3 Coordinate Attention
- **Gain** : -9K paramÃ¨tres (-1.8%) avec amÃ©lioration performance attendue
- **Foundation** : Hou et al. CVPR 2021 (Coordinate Attention)

Cette structure Ã©purÃ©e permet de se concentrer sur l'essentiel : la comparaison scientifique entre les deux approches d'attention.