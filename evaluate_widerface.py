#!/usr/bin/env python3
"""
FeatherFace WIDERFace Evaluation Script
Simplifi√© pour une ex√©cution facile depuis la racine du projet

Usage:
    python evaluate_widerface.py --model weights/mobilenet0.25_Final.pth --network mobile0.25
    python evaluate_widerface.py --model weights/v2/model_v2.pth --network mobile0.25 --version v2
"""

import os
import sys
import subprocess
import argparse
from pathlib import Path

def parse_args():
    parser = argparse.ArgumentParser(description='Evaluate FeatherFace on WIDERFace dataset')
    parser.add_argument('--model', required=True, help='Path to trained model')
    parser.add_argument('--network', default='mobile0.25', help='Network architecture')
    parser.add_argument('--version', default='v1', choices=['v1', 'v2'], help='Model version')
    parser.add_argument('--confidence_threshold', default=0.02, type=float)
    parser.add_argument('--nms_threshold', default=0.4, type=float)
    parser.add_argument('--dataset_folder', default='./data/widerface/val/images/')
    parser.add_argument('--save_folder', default='./widerface_evaluate/widerface_txt/')
    parser.add_argument('--cpu', action='store_true', help='Use CPU instead of GPU')
    parser.add_argument('--show_results', action='store_true', help='Show mAP results after evaluation')
    return parser.parse_args()

def main():
    args = parse_args()
    
    print("üöÄ FeatherFace WIDERFace Evaluation")
    print("=" * 50)
    print(f"Model: {args.model}")
    print(f"Version: {args.version}")
    print(f"Network: {args.network}")
    print("=" * 50)
    
    # V√©rifier que le mod√®le existe
    if not os.path.exists(args.model):
        print(f"‚ùå Model not found: {args.model}")
        return 1
    
    # V√©rifier que le dataset existe
    if not os.path.exists(args.dataset_folder):
        print(f"‚ùå Dataset folder not found: {args.dataset_folder}")
        print("Please ensure WIDERFace dataset is downloaded and extracted")
        return 1
    
    # Cr√©er le dossier de sauvegarde
    os.makedirs(args.save_folder, exist_ok=True)
    
    # Construire la commande de test
    cmd = [
        sys.executable, 'test_widerface.py',
        '-m', args.model,
        '--network', args.network,
        '--confidence_threshold', str(args.confidence_threshold),
        '--nms_threshold', str(args.nms_threshold),
        '--dataset_folder', args.dataset_folder,
        '--save_folder', args.save_folder
    ]
    
    if args.cpu:
        cmd.append('--cpu')
    
    print("üìä Step 1: Running inference on WIDERFace validation set...")
    print("Command:", ' '.join(cmd))
    print()
    
    # Ex√©cuter le test
    try:
        result = subprocess.run(cmd, check=True, capture_output=False)
        print("‚úÖ Inference completed successfully!")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå Inference failed: {e}")
        return 1
    
    if args.show_results:
        print("\nüìà Step 2: Computing mAP scores...")
        
        # Commande d'√©valuation
        eval_cmd = [
            sys.executable, 'widerface_evaluate/evaluation.py',
            '-p', args.save_folder,
            '-g', './widerface_evaluate/eval_tools/ground_truth'
        ]
        
        try:
            result = subprocess.run(eval_cmd, check=True, capture_output=True, text=True)
            print("‚úÖ Evaluation completed!")
            print("\nüìä Results:")
            print(result.stdout)
        except subprocess.CalledProcessError as e:
            print(f"‚ö†Ô∏è  Evaluation script failed: {e}")
            print("You can run evaluation manually:")
            print(f"cd widerface_evaluate && python evaluation.py -p {args.save_folder} -g ./eval_tools/ground_truth")
    
    print(f"\nüíæ Results saved to: {args.save_folder}")
    print("üìã To run evaluation manually:")
    print("  cd widerface_evaluate")
    print(f"  python evaluation.py -p {args.save_folder} -g ./eval_tools/ground_truth")
    
    return 0

if __name__ == '__main__':
    sys.exit(main())